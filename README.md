# BARThez-GPT-4

This repository contains the code for a text summarizer, specifically developed for the task of text abstraction. It leverages Hugging Face's transformers library to use the BartForConditionalGeneration model for training and prediction. The project involves a training phase, where a model is trained using a custom dataset and a prediction phase, where the trained model is used to summarize the text.

The aim of the project was to generate a training dataset using GPT-4 to help the model summarizing emails. 

The project article : https://medium.com/@pydathon/part-1-how-to-enhance-your-fine-tuning-journey-using-gpt-4-and-barthez-for-summarization-ed28306c27fb



@article{eddine2020barthez,
  title={BARThez: a Skilled Pretrained French Sequence-to-Sequence Model},
  author={Eddine, Moussa Kamal and Tixier, Antoine J-P and Vazirgiannis, Michalis},
  journal={arXiv preprint arXiv:2010.12321},
  year={2020}
}
